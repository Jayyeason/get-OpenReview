#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŒ‰ forumid è¯»å–å¤§ JSON çš„ abstract å­—æ®µï¼Œè°ƒç”¨ Qwen3-30B-A3B æ¨¡å‹ç”Ÿæˆè¯„å®¡ä¸è¯„åˆ†ã€‚

ç‰¹ç‚¹ï¼š
- ä»ç›®å½• /qwen_review/extracted_contents è¯»å–æ‰€æœ‰æ–‡ä»¶åä½œä¸º forumid
- åœ¨ output/all_notes_readable.json ä¸­æŸ¥æ‰¾å¯¹åº” abstractï¼ˆä½¿ç”¨ jq ä¼˜å…ˆï¼Œå¤±è´¥åˆ™å›é€€åˆ° Python è§£æï¼‰
- é»˜è®¤ç”Ÿæˆ 1 ä½ä¸¥æ ¼åº¦ä¸º 3 çš„è¯„å®¡ï¼Œæ”¯æŒé€šè¿‡å‘½ä»¤è¡ŒæŒ‡å®šä¸¥æ ¼åº¦è®¡åˆ’ï¼ˆä¾‹å¦‚ "2,3,4"ï¼‰
- æ”¯æŒæ–­ç‚¹ç»­è·‘ä¸å¹¶å‘å¤„ç†
"""

import json
import argparse
import sys
import re
import time
from pathlib import Path
from typing import Dict, List, Any, Optional, Set

import openai
from concurrent.futures import ThreadPoolExecutor, as_completed


# ============================ Prompt æ¨¡æ¿ ============================= #

BASE_REVIEW_TASK = """
## Your Review Task

### Role: The Strict, Precise & Insightful Academic Reviewer
You are a seasoned reviewer renowned for strict scrutiny, precision, and insight. You uphold the highest academic standards. Your primary mission is **strict scrutiny** to ensure that only high-quality research is advanced. You relentlessly identify core deficiencies and logical leaks, and your feedback must be **specific, clear, and executable**. Your goal is to drive authors toward fundamental improvements that meet the highest submission standards.

### Input Constraint
You are provided **only the paper abstract**. Base all judgments strictly on the abstract. **Do not speculate** about datasets, experiments, proofs, or results that are not explicitly stated. If information is missing, call it out as a limitation, reflect it in weaknesses, and set an appropriately **lower confidence**.

1. **Summary**: A brief summary of the paper's main contributions and approach (2-3 sentences).

2. **Strengths**: A substantive assessment of the strengths of the paper, touching on each of the following dimensions: originality, quality, clarity, and significance. Be broad in definitions of originality (new definitions, problem formulations, creative combinations, new domains, or removing limitations from prior results).

3. **Weaknesses**: A substantive assessment of the weaknesses of the paper. Focus on constructive and actionable insights on how the work could improve towards its stated goals. Be specific and avoid generic remarks. If you believe the contribution lacks novelty, provide references and explanations; if experiments are insufficient, explain why and exactly what is missing.

4. **Questions**: List up and carefully describe any questions and suggestions for the authors. Think of things where a response from the author can change your opinion, clarify a confusion, or address a limitation. This is important for a productive rebuttal and discussion phase.

5. **Soundness** (1-4): Rate the paper's soundness. Are the central claims adequately supported with evidence? Are the experimental setup and research methodology sound?
   - 1: Poor
   - 2: Fair
   - 3: Clear and structured
   - 4: Excellent

6. **Presentation** (1-4): Rate the quality of presentation. This should take into account the writing style and clarity, presentation of figures and diagrams, as well as contextualization relative to prior work.
   - 1: Poor
   - 2: Fair
   - 3: Good
   - 4: Excellent

7. **Contribution** (1-4): Rate the quality of the overall contribution this paper makes to the research area being studied. Are the questions being asked important? Does the paper bring significant originality of ideas and/or execution? Are the results valuable to share with the broader ICLR community?
   - 1: Poor
   - 2: Fair
   - 3: Good
   - 4: Excellent

8. **Rating** (1, 3, 5, 6, 8, 10): Provide an overall score for this submission:
   - 1: Strong reject
   - 3: Reject, not good enough
   - 5: Marginally below the acceptance threshold
   - 6: Marginally above the acceptance threshold
   - 8: Accept, good paper
   - 10: Strong accept, should be highlighted at the conference

9. **Confidence** (1-5): Provide a confidence score for your assessment:
   - 1: Unable to assess this paper, need opinion from different reviewers
   - 2: Willing to defend assessment, but quite likely did not understand central parts or unfamiliar with related work
   - 3: Fairly confident in assessment. Possible that did not understand some parts or unfamiliar with some related work
   - 4: Confident in assessment, but not absolutely certain. Unlikely but not impossible that did not understand some parts
   - 5: Absolutely certain about assessment. Very familiar with related work and checked details carefully

## Output Format

You must respond with a JSON object in the following format:
```json
{
  "summary": "...",
  "strengths": "...",
  "weaknesses": "...",
  "questions": "...",
  "rating": <1, 3, 5, 6, 8, or 10>,
  "confidence": <1-5>,
  "soundness": <1-4>,
  "presentation": <1-4>,
  "contribution": <1-4>
}
```

**Important**:
- `rating` must be one of: 1, 3, 5, 6, 8, 10
- `confidence`, `soundness`, `presentation`, `contribution` must be integers in their respective ranges

You may use <think> tags to organize your thoughts before providing the JSON response. The final JSON object should come after your reasoning."""

SYSTEM_PROMPT_LEVEL_1 = """You are an expert academic reviewer for a top-tier machine learning conference (ICLR).

## Your Reviewer Profile
**You are a Level 1 Encouraging Reviewer**

- **Philosophy**: You believe in nurturing innovation and giving researchers opportunities to develop ideas.
- **What you value most**: Novelty, creativity, potential impact, and fresh perspectives.
- **How you view flaws**: Minor issues are acceptable if the core idea is interesting. Limitations are seen as future work opportunities.
- **Your threshold for acceptance**: Does this paper bring something interesting to the community? If yes, you support its publication.
- **How you write weaknesses**: You frame issues constructively as "suggestions for improvement" rather than dealbreakers.
- **Typical ratings**: You commonly give 8 (good papers with novelty) or 10 (excellent innovative work).

""" + BASE_REVIEW_TASK

SYSTEM_PROMPT_LEVEL_2 = """You are an expert academic reviewer for a top-tier machine learning conference (ICLR).

## Your Reviewer Profile
**You are a Level 2 Supportive Reviewer**

- **Philosophy**: You appreciate solid scientific work and want to help good research get published.
- **What you value most**: Sound methodology, clear contributions, and well-executed experiments.
- **How you view flaws**: You acknowledge limitations but weigh them against the overall contribution.
- **Your threshold for acceptance**: Is this a solid piece of work that advances the field? You give borderline papers the benefit of doubt.
- **How you write weaknesses**: You point out concerns but emphasize the paper's merits.
- **Typical ratings**: You commonly give 6 (marginally acceptable) or 8 (solid accept).

""" + BASE_REVIEW_TASK

SYSTEM_PROMPT_LEVEL_3 = """You are an expert academic reviewer for a top-tier machine learning conference (ICLR).

## Your Reviewer Profile
**You are a Level 3 Objective Reviewer**

- **Philosophy**: You apply standard conference criteria fairly and consistently.
- **What you value most**: Balance between novelty, soundness, clarity, and significance.
- **How you view flaws**: Issues are noted objectively; significant problems affect your rating proportionally.
- **Your threshold for acceptance**: Does this paper meet the expected quality bar for ICLR?
- **How you write weaknesses**: You provide balanced critique with both strengths and weaknesses carrying equal weight.
- **Typical ratings**: You commonly give 5 (marginally below threshold) or 6 (marginally above threshold).

""" + BASE_REVIEW_TASK

SYSTEM_PROMPT_LEVEL_4 = """You are an expert academic reviewer for a top-tier machine learning conference (ICLR).

## Your Reviewer Profile
**You are a Level 4 Rigorous Reviewer**

- **Philosophy**: You hold papers to high standards because ICLR should showcase strong research.
- **What you value most**: Rigorous experimental validation, strong baselines, thorough analysis, and clear novelty over prior work.
- **How you view flaws**: Even small issues raise concerns. You need convincing evidence for all claims.
- **Your threshold for acceptance**: Only clear, well-executed contributions with strong empirical support should be accepted.
- **How you write weaknesses**: You identify issues in depth and question claims that lack sufficient support.
- **Typical ratings**: You commonly give 3 (reject, not good enough) or 5 (marginally below threshold).

""" + BASE_REVIEW_TASK

SYSTEM_PROMPT_LEVEL_5 = """You are an expert academic reviewer for a top-tier machine learning conference (ICLR).

## Your Reviewer Profile
**You are a Level 5 Highly Critical Reviewer**

- **Philosophy**: ICLR is a top venue; only exceptional work should be published.
- **What you value most**: Groundbreaking ideas, flawless execution, comprehensive experiments, and significant impact.
- **How you view flaws**: You scrutinize every detail. Missing baselines, incomplete experiments, or unclear novelty are major concerns.
- **Your threshold for acceptance**: This paper must be exceptional - truly advancing the field with rigorous validation.
- **How you write weaknesses**: You point out all limitations, gaps, and areas where the paper falls short of the highest standards.
- **Typical ratings**: You commonly give 1 (strong reject) or 3 (reject, not good enough).

""" + BASE_REVIEW_TASK

SYSTEM_PROMPTS = {
    1: SYSTEM_PROMPT_LEVEL_1,
    2: SYSTEM_PROMPT_LEVEL_2,
    3: SYSTEM_PROMPT_LEVEL_3,
    4: SYSTEM_PROMPT_LEVEL_4,
    5: SYSTEM_PROMPT_LEVEL_5,
}

USER_PROMPT_TEMPLATE = """## Paper Abstract (only input)

{paper_abstract}

## Constraints
- **Strictly abstract-only**: Base your review solely on the abstract provided. You do not have access to the full paper, methods, experiments, datasets, or detailed results.
- **No speculation**: Do not assume or infer information that is not explicitly stated in the abstract. This includes:
  - Specific experimental setups, datasets, or baselines
  - Detailed methodology or implementation details
  - Quantitative results, performance metrics, or statistical significance
  - Proofs, theoretical guarantees, or technical details
  - Related work comparisons beyond what is mentioned
- **Missing information as weakness**: If key information is missing from the abstract (e.g., no mention of experiments, unclear methodology, vague contributions), explicitly identify these gaps in the weaknesses section.
- **Confidence calibration**: Set your confidence score (1-5) appropriately:
  - Lower confidence (2-3) is typical for abstract-only reviews, as many details are unavailable
  - Only use higher confidence (4-5) if the abstract is unusually detailed and comprehensive
  - If the abstract lacks critical information, use confidence 2 or lower
- **Rating adjustment**: Avoid high ratings (8-10) if the abstract lacks sufficient detail to assess the work's quality. Missing experimental validation or unclear contributions should lower the rating.
- **Focus on what's stated**: Evaluate the abstract's clarity, stated contributions, problem formulation, and potential significance based only on what is explicitly written.
"""


class ReviewerAI:
    def __init__(
        self,
        base_url: str = "http://10.176.59.108:8003/v1",
        model_name: str = "qwen3-30b-a3b",
    ):
        self.client = openai.OpenAI(api_key="EMPTY", base_url=base_url)
        self.model_name = model_name
        self.system_prompts = SYSTEM_PROMPTS

    def build_review_prompt(self, paper_abstract: str, max_content_length: int = 4000) -> str:
        if len(paper_abstract) > max_content_length:
            paper_abstract = paper_abstract[:max_content_length] + "\n\n[æ‘˜è¦å·²æˆªæ–­...]"
        return USER_PROMPT_TEMPLATE.format(paper_abstract=paper_abstract)

    def generate_review(
        self,
        paper_abstract: str,
        strictness: int = 3,
        temperature: float = 0.7,
        max_tokens: int = 4000,
    ) -> Dict[str, Any]:
        prompt = self.build_review_prompt(paper_abstract)
        try:
            system_prompt = self.system_prompts.get(strictness, self.system_prompts[3])
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt},
                ],
                temperature=temperature,
                max_tokens=max_tokens,
            )
            content = response.choices[0].message.content
            content = content.strip()

            # å»é™¤ <think> æ®µ
            if '<think>' in content.lower():
                think_patterns = ['</think>', '</Think>', '</THINK>']
                for pattern in think_patterns:
                    if pattern.lower() in content.lower():
                        idx = content.lower().find(pattern.lower())
                        if idx != -1:
                            content = content[idx + len(pattern):].strip()
                            break
                else:
                    json_start = content.find('{')
                    if json_start != -1:
                        content = content[json_start:]

            # å»é™¤ markdown ä»£ç å—
            if content.startswith("```json"):
                content = content[7:]
            elif content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()

            # è‹¥å¼€å¤´ä»æœ‰æ‚è´¨ï¼Œå®šä½åˆ°ç¬¬ä¸€ä¸ª {
            if not content.startswith('{'):
                json_start = content.find('{')
                if json_start != -1:
                    content = content[json_start:]

            # ä¿®å¤æ— æ•ˆè½¬ä¹‰
            def fix_escape(match):
                char = match.group(1)
                if char in ['"', '\\', '/', 'b', 'f', 'n', 'r', 't', 'u']:
                    return match.group(0)
                else:
                    return '\\\\' + char
            content = re.sub(r'\\(.)', fix_escape, content)

            review_data = json.loads(content)
            return review_data

        except json.JSONDecodeError as e:
            # ä¿å­˜åŸå§‹å“åº”å†…å®¹çš„å‰500å­—ç¬¦ç”¨äºè°ƒè¯•
            error_context = ""
            if 'content' in locals():
                error_pos = getattr(e, 'pos', None)
                if error_pos:
                    start = max(0, error_pos - 100)
                    end = min(len(content), error_pos + 100)
                    error_context = f"\né”™è¯¯ä½ç½®é™„è¿‘å†…å®¹: ...{content[start:end]}..."
                else:
                    error_context = f"\nåŸå§‹å“åº”å‰500å­—ç¬¦: {content[:500]}"
            
            print(f"  âš ï¸  JSONè§£æå¤±è´¥: {e}")
            if error_context:
                print(f"  {error_context}")
            
            return {
                "summary": f"Failed to parse JSON: {str(e)}",
                "strengths": "",
                "weaknesses": "",
                "questions": "",
                "rating": -1,
                "confidence": -1,
                "soundness": -1,
                "presentation": -1,
                "contribution": -1,
                "error": str(e),
                "raw_content_preview": content[:500] if 'content' in locals() else "N/A",
            }
        except Exception as e:
            return {
                "summary": f"Error: {str(e)}",
                "strengths": "",
                "weaknesses": "",
                "questions": "",
                "rating": -1,
                "confidence": -1,
                "soundness": -1,
                "presentation": -1,
                "contribution": -1,
                "error": str(e),
            }


def format_review_content(review_data: Dict[str, Any]) -> Dict[str, Any]:
    content: Dict[str, Any] = {}
    for key in ['summary', 'strengths', 'weaknesses', 'questions']:
        if key in review_data:
            content[key] = {"value": review_data[key]}
    for key in ['rating', 'confidence', 'soundness', 'presentation', 'contribution']:
        if key in review_data and review_data[key] != -1:
            content[key] = {"value": review_data[key]}
    return content


# è¯»å–extracted_contendæ–‡ä»¶å¤¹ä¸‹çš„è®ºæ–‡åç§°
def list_forum_ids(input_dir: Path, limit: Optional[int] = None) -> List[str]:
    files = sorted(input_dir.glob('*.txt'))
    if limit is not None:
        files = files[:limit]
    return [f.stem for f in files]


def build_forum_abstract_map(all_notes_path: Path, needed_ids: Set[str]) -> Dict[str, str]:
    """æ„å»º forum -> abstract æ˜ å°„ï¼ˆçº¯ Python è§£æï¼‰ã€‚
    è§„åˆ™ï¼š
    - ä»…ä½¿ç”¨æŠ•ç¨¿ noteï¼ˆid == forumï¼‰
    - æŠ½å– abstract å€™é€‰ï¼šabstract / TL;DR / tl;dr / TLDR / paper_abstract / Abstract
    - ä»…ä¿ç•™éç©ºæ‘˜è¦ï¼Œé¿å…ç©ºå€¼è¦†ç›–
    - æ”¯æŒä¸¤ç§è¾“å…¥ï¼šæ ‡å‡† JSON æ•°ç»„æˆ– NDJSON è¡Œæµ
    """
    mapping: Dict[str, str] = {}

    def extract_abstract_variants_from_content(content: Dict[str, Any]) -> Optional[str]:
        if not isinstance(content, dict):
            return None
        candidates = ['abstract', 'Abstract', 'paper_abstract', 'tl;dr', 'TL;DR', 'TLDR']
        for k in candidates:
            v = content.get(k)
            if isinstance(v, dict):
                v = v.get('value')
            if isinstance(v, str):
                v = v.strip()
            if v:
                return v
        return None

    # è¯»å–æ–‡ä»¶ï¼šä¼˜å…ˆæŒ‰æ ‡å‡† JSON æ•°ç»„è§£æï¼Œå¤±è´¥åˆ™æŒ‰ NDJSON é€è¡Œè§£æ
    try:
        with open(all_notes_path, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
                iterable = data if isinstance(data, list) else []
            except json.JSONDecodeError:
                # å¯èƒ½æ˜¯ NDJSONï¼Œå›é€€åˆ°é€è¡Œè§£æ
                f.seek(0)
                iterable = []
                for line in f:
                    s = line.strip()
                    if not s:
                        continue
                    try:
                        obj = json.loads(s)
                        iterable.append(obj)
                    except Exception:
                        continue
            except MemoryError:
                print('âŒ å†…å­˜ä¸è¶³ï¼Œæ— æ³•åŠ è½½å¤§ JSONã€‚è¯·å‡å°‘ needed_ids æˆ–æ‹†åˆ†æ–‡ä»¶ã€‚')
                return mapping
    except FileNotFoundError:
        print(f'âŒ æ–‡ä»¶ä¸å­˜åœ¨: {all_notes_path}')
        return mapping

    # ä»…æå–æŠ•ç¨¿ noteï¼ˆid == forumï¼‰ï¼Œä¸”ä»…å½“æ‘˜è¦éç©ºæ—¶è®¾ç½®ä¸€æ¬¡
    for item in iterable:
        if not isinstance(item, dict):
            continue
        fid = item.get('forum')
        if not fid or fid not in needed_ids:
            continue
        if item.get('id') != fid:
            continue
        content = item.get('content') or {}
        abstract = extract_abstract_variants_from_content(content) or ''
        if abstract and fid not in mapping:
            mapping[fid] = abstract
    return mapping


def process_single_forum(
    forum_id: str,
    abstract_text: str,
    reviewer_ai: ReviewerAI,
    strictness_levels: List[int],
) -> Dict[str, Any]:
    reviews: List[Dict[str, Any]] = []
    print(f"  æ‘˜è¦é•¿åº¦: {len(abstract_text)}")
    for level in strictness_levels:
        start = time.time()
        review_data = reviewer_ai.generate_review(paper_abstract=abstract_text, strictness=level)
        elapsed = time.time() - start
        formatted = format_review_content(review_data)
        reviews.append({
            'reviewer_id': f'reviewer_{level}',
            'strictness': level,
            'review': formatted,
            'elapsed_sec': round(elapsed, 2),
        })
    return {
        'paper_id': forum_id,
        'source': 'abstract_only',
        'abstract': abstract_text,
        'reviews': reviews,
    }


def main():
    parser = argparse.ArgumentParser(
        description='æŒ‰ abstract è°ƒç”¨ Qwen3-30B-A3B ç”Ÿæˆè¯„å®¡ä¸è¯„åˆ†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''ç¤ºä¾‹ï¼š
  python model-service/qwen3-30B-abstract-reviewer.py \
    --input-dir /remote-home1/bwli/get_open_review/qwen_review/extracted_contents \
    --notes-json /remote-home1/bwli/get_open_review/output/all_notes_readable.json \
    --output model-service/qwen3-30B-abstract-reviews.json \
    --strictness-plan 3 --workers 2 --limit 50
'''
    )

    # é»˜è®¤è¾“å‡ºåˆ°è„šæœ¬åŒç›®å½•ï¼Œé¿å…åœ¨ä¸åŒå·¥ä½œç›®å½•ä¸‹ç›¸å¯¹è·¯å¾„å¤±æ•ˆ
    default_output_path = str(Path(__file__).resolve().parent / 'qwen3-30B-abstract-reviews.json')
    parser.add_argument('--input-dir', default='/remote-home1/bwli/get_open_review/qwen_review/extracted_contents', help='åŒ…å« forumid çš„æ–‡æœ¬æ–‡ä»¶ç›®å½•')
    parser.add_argument('--notes-json', default='/remote-home1/bwli/get_open_review/output/all_notes_readable.json', help='åŒ…å«æ‰€æœ‰ notes çš„å¤§ JSON æ–‡ä»¶')
    parser.add_argument('--output', default=default_output_path, help='è¾“å‡º JSON æ–‡ä»¶')
    parser.add_argument('--base-url', default='http://10.176.59.105:8004/v1', help='æ¨¡å‹ API Base URL')
    parser.add_argument('--model', default='qwen3-30b-a3b', help='æ¨¡å‹åç§°')
    parser.add_argument('--strictness-plan', default='2,3,4', help='é€—å·åˆ†éš”çš„ä¸¥æ ¼åº¦åˆ—è¡¨ï¼Œä¾‹å¦‚ "2,3,4" æˆ– "1,2,3,4,5"')
    parser.add_argument('--workers', type=int, default=1, help='å¹¶è¡Œçº¿ç¨‹æ•°')
    parser.add_argument('--limit', type=int, default=None, help='åªå¤„ç†å‰ N ä¸ª forumid')

    args = parser.parse_args()

    input_dir = Path(args.input_dir)
    notes_json = Path(args.notes_json)
    output_path = Path(args.output)

    if not input_dir.exists():
        print(f'âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}')
        sys.exit(1)
    if not notes_json.exists():
        print(f'âŒ å¤§ JSON æ–‡ä»¶ä¸å­˜åœ¨: {notes_json}')
        sys.exit(1)

    # åˆ—å‡º forumid
    forum_ids = list_forum_ids(input_dir, limit=args.limit)
    print(f'âœ“ å¾…å¤„ç† forumid æ•°é‡: {len(forum_ids)}')

    # æ–­ç‚¹ç»­è·‘åŠ è½½
    results: Dict[str, Any] = {}
    if output_path.exists():
        try:
            with open(output_path, 'r', encoding='utf-8') as f:
                existing = json.load(f)
            if isinstance(existing, dict):
                results = existing
                print(f'â†» è½½å…¥å·²æœ‰ç»“æœï¼š{len(results)} æ¡ï¼Œç”¨äºç»­è·‘')
        except Exception as e:
            print(f'âš ï¸  è¯»å–å·²æœ‰è¾“å‡ºå¤±è´¥ï¼Œå¿½ç•¥ç»­è·‘æ•°æ®: {e}')

    # éœ€è¦çš„ id é›†åˆï¼ˆè¿‡æ»¤å·²å®Œæˆï¼‰
    def needs_work(fid: str, strictness_levels: List[int]) -> bool:
        entry = results.get(fid)
        if not entry:
            return True
        reviews = entry.get('reviews', [])
        done_levels = {r.get('strictness') for r in reviews if isinstance(r.get('strictness'), int)}
        for lv in strictness_levels:
            if lv not in done_levels:
                return True
        return False

    strictness_levels = [int(x) for x in args.strictness_plan.split(',') if x.strip()]
    print(f'ä½¿ç”¨ä¸¥æ ¼åº¦è®¡åˆ’: {strictness_levels}')
    todo_ids = [fid for fid in forum_ids if needs_work(fid, strictness_levels)]
    print(f'âœ“ éœ€è¦ç”Ÿæˆçš„æ¡ç›®: {len(todo_ids)}')

    # å»ºç«‹ forum -> abstract æ˜ å°„ï¼ˆåŒ…å«å¾…å¤„ç†ä¸å·²æœ‰ç»“æœä¸¤éƒ¨åˆ†ï¼Œä¾¿äºè¡¥é½å·²æœ‰é¡¹çš„æ‘˜è¦ï¼‰
    existing_ids: Set[str] = set(results.keys())
    needed_set: Set[str] = set(todo_ids) | existing_ids
    forum_to_abstract = build_forum_abstract_map(notes_json, needed_set)
    missing = needed_set - set(forum_to_abstract.keys())
    if missing:
        print(f'âš ï¸  æœ‰ {len(missing)} ä¸ª forumid æœªåœ¨å¤§ JSON ä¸­æ‰¾åˆ°æ‘˜è¦ï¼ˆå°†è¾“å‡ºç©ºæ‘˜è¦ï¼‰ã€‚')

    # å…ˆä¸ºå·²æœ‰ç»“æœè¡¥é½æ‘˜è¦å­—æ®µï¼ˆä¸è§¦å‘é‡æ–°è¯„å®¡ï¼‰
    patched_existing = 0
    if existing_ids:
        for fid in existing_ids:
            entry = results.get(fid) or {}
            if not entry.get('abstract'):
                abs_text = forum_to_abstract.get(fid, '')
                if abs_text:
                    entry['abstract'] = abs_text
                    results[fid] = entry
                    patched_existing += 1
        if patched_existing:
            save_results(results, output_path)
            print(f'â†» å·²ä¸º {patched_existing} æ¡æ—¢æœ‰ç»“æœè¡¥é½æ‘˜è¦å­—æ®µ')

    # åˆå§‹åŒ–è¯„å®¡ AI
    reviewer_ai = ReviewerAI(base_url=args.base_url, model_name=args.model)

    def save_results(results_dict: Dict[str, Any], path: Path):
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        try:
            path.parent.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, ensure_ascii=False, indent=2)

    # ä»»åŠ¡ç”Ÿæˆ
    tasks: List[str] = todo_ids

    if args.workers == 1:
        for idx, fid in enumerate(tasks, 1):
            abstract_text = forum_to_abstract.get(fid, '')
            if not abstract_text:
                print(f'âš ï¸  æ‘˜è¦ä¸ºç©ºï¼Œforumid={fid}ï¼ˆå°†ä»¥ç©ºæ‘˜è¦è¿›è¡Œè¯„å®¡ï¼‰')
            entry = process_single_forum(fid, abstract_text, reviewer_ai, strictness_levels)
            results[fid] = entry
            save_results(results, output_path)
            print(f'ğŸ’¾ å·²ä¿å­˜ ({idx}/{len(tasks)}) - {fid}')
    else:
        with ThreadPoolExecutor(max_workers=args.workers) as executor:
            futures = {
                executor.submit(process_single_forum, fid, forum_to_abstract.get(fid, ''), reviewer_ai, strictness_levels): fid
                for fid in tasks
            }
            for idx, future in enumerate(as_completed(futures), 1):
                fid = futures[future]
                entry = future.result()
                results[fid] = entry
                save_results(results, output_path)
                print(f'ğŸ’¾ å·²ä¿å­˜ ({idx}/{len(tasks)}) - {fid}')

    # ç»Ÿè®¡è¾“å‡º
    print('\n======== ç»Ÿè®¡ ========')
    print(f'æ€»æ¡ç›®: {len(results)}')
    total_reviews = 0
    success = 0
    ratings: List[int] = []
    missing_abstract = 0
    for entry in results.values():
        if not entry.get('abstract'):
            missing_abstract += 1
        reviews = entry.get('reviews', [])
        total_reviews += len(reviews)
        for r in reviews:
            rating = (r.get('review') or {}).get('rating', {}).get('value', -1)
            if isinstance(rating, int) and rating >= 0:
                success += 1
                ratings.append(rating)
    print(f'æ€»è¯„å®¡æ•°: {total_reviews}, æˆåŠŸ: {success}, å¤±è´¥: {total_reviews - success}')
    print(f'æ‘˜è¦ç¼ºå¤±æ¡ç›®: {missing_abstract}')
    if ratings:
        print(f'è¯„åˆ†èŒƒå›´: {min(ratings)} - {max(ratings)}, å¹³å‡: {sum(ratings)/len(ratings):.2f}')
    print(f'âœ… ç»“æœå·²ä¿å­˜: {output_path.resolve()}')


if __name__ == '__main__':
    main()